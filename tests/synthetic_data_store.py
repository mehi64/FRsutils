"""
Synthetic Test Datasets for Fuzzy Components

Provides structured test datasets for verifying T-norms, Implicators, and other fuzzy components.
"""

import numpy as np

def get_tnorm_scalar_testsets():
    return [
        {
            "name": "basic_tnorms_DS_1",
            "a_b": np.array([
                [0.73, 0.18],
                [0.18, 0.73],
                [0.88, 0.88],
                [0.91, 0.48],
                [1.00, 1.00],
                [0.00, 0.00],
                [1.00, 0.65],
                [0.37, 1.00]
            ]),
            "expected": {
                "minimum": np.array([0.18, 0.18, 0.88, 0.48, 1.0, 0.0, 0.65, 0.37]),
                "product": np.array([0.1314, 0.1314, 0.7744, 0.4368, 1.00, 0.00, 0.65, 0.37]),
                "lukasiewicz": np.array([0.0, 0.0, 0.76, 0.39, 1.00, 0.00, 0.65, 0.37]),
                "drastic_product": np.array([0.00, 0.00, 0.00, 0.00, 1.00, 0.00, 0.65, 0.37]),
                "hamacher_product": np.array([0.168764, 0.168764, 0.785714, 0.458246, 1.00, 0.00, 0.65, 0.37]),
                "einstein": np.array([0.107581, 0.107581, 0.763407, 0.417271, 1.00, 0.00, 0.65, 0.37]),
                "nilpotent_min": np.array([0.00, 0.00, 0.88, 0.48, 1.00, 0.00, 0.65, 0.37]),
                "yager_p=0.835": np.array([0.00, 0.00, 0.724771, 0.332934, 1.00, 0.00, 0.65, 0.37])
            }
        }
    ]

def get_tnorm_reduce_testsets():
    return [
        {
            "name": "tnorm_reduce",
            "similarity_matrix": np.array([
            [1.0,     0.2673,  0.25456, 0.1197,  0.09504],
            [0.2673,  1.0,     0.0658,  0.1624,  0.054  ],
            [0.25456, 0.0658,  1.0,     0.3157,  0.53217],
            [0.1197,  0.1624,  0.3157,  1.0,     0.53872],
            [0.09504, 0.054,   0.53217, 0.53872, 1.0     ]
        ]),
            "label_mask" : np.array([
            [1.0, 1.0, 0.0, 1.0, 0.0],
            [1.0, 1.0, 0.0, 1.0, 0.0],
            [0.0, 0.0, 1.0, 0.0, 1.0],
            [1.0, 1.0, 0.0, 1.0, 0.0],
            [0.0, 0.0, 1.0, 0.0, 1.0]
        ]),
            "expected": 
            {
                "minimum_outputs": np.array([
                [1.0,     0.2673,  0.0,     0.1197,  0.0],
                [0.2673,  1.0,     0.0,     0.1624,  0.0],
                [0.0,     0.0,     1.0,     0.0,     0.53217],
                [0.1197,  0.1624,  0.0,     1.0,     0.0],
                [0.0,     0.0,     0.53217, 0.0,     1.0]]),
                
                "product_outputs": np.array([
                [1.0,     0.2673,  0.0,     0.1197,  0.0],
                [0.2673,  1.0,     0.0,     0.1624,  0.0],
                [0.0,     0.0,     1.0,     0.0,     0.53217],
                [0.1197,  0.1624,  0.0,     1.0,     0.0],
                [0.0,     0.0,     0.53217, 0.0,     1.0]]),
            
                "luk_outputs" : np.array([
                [1.0,	    0.2673, 0.0,	0.1197,	0.0],
                [0.2673,	1.0,	0.0,	0.1624,	0.0],
                [0.0,	    0.0,	1.0,	0.0,	0.53217],
                [0.1197,	0.1624,	0.0,	1.0,	0.0],
                [0.0,	    0.0,	0.53217,0.0,	1.0]])
            }
        }
    ]

def get_implicator_scalar_testsets():
    return [
        {
            "name": "basic_implicators",
            "a_b": np.array([
                [0.73, 0.18],
                [0.18, 0.73],
                [0.88, 0.88],
                [0.91, 0.48],
                [1.00, 1.00],
                [0.00, 0.00]
            ]),
            "expected": {
                "gaines": np.array([0.24657534246, 1.0, 1.0, 0.527472527, 1.0, 1.0]),
                "goedel": np.array([0.18, 1.0, 1.0, 0.48, 1.0, 1.0]),
                "lukasiewicz": np.array([0.45, 1.00, 1.00, 0.57, 1.00, 1.00]),
                "kleene-dienes": np.array([0.27, 0.82, 0.88, 0.48, 1.00, 1.00]),
                "reichenbach": np.array([0.4014, 0.9514, 0.8944, 0.5268, 1.00, 1.00])
            }
        }
    ]


